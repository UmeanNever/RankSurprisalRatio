<p align="center">
 <h2 align="center"> Rank-Surprisal Ratio (RSR) </h2>
 <p align="center"> From the paper <strong>"Which Reasoning Trajectories Teach Students to Reason Better? <br>
    A Simple Metric of Informative Alignment"</strong> </p>
</p>

<p align="center">
 <a href="https://github.com/UmeanNever/RankSurprisalRatio/blob/main/LICENSE"><img alt="GitHub license" src="https://img.shields.io/github/license/UmeanNever/RankSurprisalRatio"></a>
 <a href="https://arxiv.org/abs/2601.14249"><img alt="Paper" src="https://img.shields.io/badge/üìñ-Paper-red"></a>
 <a href="https://huggingface.co/datasets/Umean/RSR_data"><img alt="Data" src="https://img.shields.io/badge/üìÄ-Data-blue"></a>
</p>

<p align="center">
  <img src="/assets/rsr_def.png" alt="RSR definition." width="350"/>
  <br>
  <em>
    Rank values are clipped; see Eq. 7 in the paper for the formal definition.
  </em>
</p>

## üìã Overview

In this work, we investigate data‚Äìstudent suitability in reasoning distillation and introduce **Rank-Surprisal Ratio** (RSR), a simple yet effective metric for **identifying suitable reasoning trajectories for a given student**.  

RSR is defined as the ratio of a trajectory‚Äôs average token-wise rank to its average negative log-likelihood (surprisal), and **is straightforward to compute and interpret**.

- üìñ **Paper**: [Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment](https://arxiv.org/abs/2601.14249)
- üõ†Ô∏è **Code**: Available in this repository, providing **a clean and efficient implementation for computing the RSR metric**.
- üìÄ **Data**: Available on [Hugging Face](https://huggingface.co/datasets/Umean/RSR_data). We release 33 math reasoning trajectory datasets used in our experiments, generated by 11 different teacher models. We also release RSR-selected datasets for 5 student models. These datasets can be directly used for reasoning distillation.

<p align="center">
  <img src="/assets/rsr.png" alt="llustration of the intuition behind RSR." width="450"/>
  <br>
  <em>
    Figure: Illustration of the intuition behind RSR. <br> Suitable reasoning trajectories should balance informativeness and alignment, <br> having low absolute probability while their tokens remain relatively high-ranked under the student model.
  </em>
</p>

Motivated by our analysis, RSR jointly captures a trajectory's informativeness and alignment with the student‚Äôs behavior, favoring trajectories with low absolute probability but relatively high-ranked tokens.

Across five student models and reasoning trajectories from 11 diverse teachers, RSR strongly correlates with post-training reasoning performance (**average Spearman 0.86**), consistently outperforming existing metrics. We further demonstrate its practical utility in both **trajectory selection** and **teacher selection**.

For more information and a detailed introduction to RSR, please refer to our paper.

## üöÄ Quick Start
Our codebase supports the computation of our lightweight suitability metric, the **Rank-Surprisal Ratio** (RSR), given teacher trajectories and student models. The code has been cleaned up from our original implementation and streamlined to focus on RSR computation.

- `rsr_launch.py` serves as the **entry-point** script for computing RSR. You can modify the global variables in this file according to your experimental setup and then run it to start the computation. Please refer to the provided datasets for the expected data format.  
- `rsr_cal.py` implements the core computation logic. It includes placeholders and explanatory comments to facilitate easy customization.

The current implementation has minimal dependencies, relying primarily on `torch` and `transformers`. While not strictly required, we recommend the following Python environment configuration:

* torch==2.7.0
* transformers==4.53.3
* flash-attn==2.8.3 (optional, but substantially boosts speed)
* Python 3.12
* CUDA 12.8

See `requirements.txt` for the complete list of Python package dependencies. You can install them using `pip install -r requirements.txt`. We recommend installing `flash-attn` via pre-built wheels corresponding to your specific Python, CUDA, and PyTorch environment.

In our experiments, computing RSR over the 5,000-trajectory dataset with a context length of 32,768 using a 7B
model typically takes under one hour on a single H200 GPU with FlashAttention enabled. For further computational details, see Appendix C.1 of our paper.

## üìù Citation

If you find our work helpful, please consider citing our paper:

```bibtex
@article{yang2026reasoning,
  title={Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment},
  author={Yuming Yang and Mingyoung Lai and Wanxu Zhao and Xiaoran Fan and Zhiheng Xi and Mingqi Wu and Chiyue Huang and Jun Zhao and Haijun Lv and Jian Tong and Yunhua Zhou and Yicheng Zou and Qipeng Guo and Tao Gui and Qi Zhang and Xuanjing Huang},
  journal={arXiv preprint arXiv:2601.14249},
  year={2026}
}
```
