<p align="center">
 <h2 align="center"> Which Reasoning Trajectories Teach Students to Reason Better? <br> A Simple Metric of Informative Alignment </h2>
</p>

<p align="center">
 <a href="https://github.com/UmeanNever/RankSurprisalRatio/blob/main/LICENSE"><img alt="GitHub license" src="https://img.shields.io/github/license/UmeanNever/RankSurprisalRatio"></a>
 <a href="https://arxiv.org/abs/2601.14249"><img alt="Paper" src="https://img.shields.io/badge/üìñ-Paper-red"></a>
 <a href="https://huggingface.co/datasets/Umean/RSR_data"><img alt="Data" src="https://img.shields.io/badge/üìÄ-Data-blue"></a>
</p>

## üìã Overview

In this work, we investigate data‚Äìstudent suitability in reasoning distillation and introduce **Rank-Surprisal Ratio** (RSR), a simple yet effective metric for identifying suitable reasoning trajectories for a given student.  
Motivated by our analysis, RSR jointly captures a trajectory's informativeness and alignment with the student‚Äôs behavior, favoring trajectories with low absolute probability but relatively high-ranked tokens.

- üìñ **Paper**: [Read our paper on arXiv](https://arxiv.org/abs/2601.14249)
- üõ†Ô∏è **Code**: Available in this repository, providing an implementation for computing the RSR metric.
- üìÄ **Data**: Available on [Hugging Face](https://huggingface.co/datasets/Umean/RSR_data). We release 33 math reasoning trajectory datasets used in our experiments, generated by 11 teacher models (3 datasets per teacher). These datasets can be directly used for reasoning distillation.

For more information and a detailed introduction to RSR, please refer to our paper.

<p align="center">
  <img src="/assets/rsr.png" alt="llustration of the intuition behind RSR." width="450"/>
  <br>
  <em>
    Figure 1: Illustration of the intuition behind RSR. <br> Suitable reasoning trajectories should balance informativeness and alignment, having low absolute probability while their tokens remain relatively high-ranked under the student model.
  </em>
</p>

## üöÄ Quick Start
Our codebase supports the computation of our lightweight suitability metric, the **Rank-Surprisal Ratio** (RSR), given teacher trajectories and student models.

- `rsr_launch.py` serves as the entry-point script for computing RSR. You can modify the global variables in this file according to your experimental setup and then run it to start the computation. Please refer to the provided datasets for the expected data format.  
- `rsr_cal.py` implements the core computation logic. It includes placeholders and explanatory comments to facilitate easy customization. The code has been cleaned up from our original implementation and streamlined to focus on RSR computation.

The current implementation has minimal dependencies, relying primarily on `torch` and `transformers`. While not strictly required, we recommend the following Python environment configuration:

* torch==2.7.0
* transformers==4.53.3
* flash-attn==2.8.3 (optional, but substantially boosts speed)
* Python 3.12
* CUDA 12.8

See `requirements.txt` for the complete list of Python package dependencies. You can install them using `pip install -r requirements.txt`. We recommend installing `flash-attn` via pre-built wheels corresponding to your specific Python, CUDA, and PyTorch environment.

In our experiments, computing RSR on the 5,000-trajectory dataset typically takes about one hour on a single H200 GPU with FlashAttention enabled. For further computational details, see Appendix C.1 of our paper.

## üìù Citation

If you find our work helpful, please consider citing our paper:

```bibtex
@article{yang2026reasoning,
  title={Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment},
  author={Yuming Yang and Mingyoung Lai and Wanxu Zhao and Xiaoran Fan and Zhiheng Xi and Mingqi Wu and Chiyue Huang and Jun Zhao and Haijun Lv and Jian Tong and Yunhua Zhou and Yicheng Zou and Qipeng Guo and Tao Gui and Qi Zhang and Xuanjing Huang},
  journal={arXiv preprint arXiv:2601.14249},
  year={2026}
}
```
